{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Important Section"
      ],
      "metadata": {
        "id": "ooHwFMMBlGCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -U langgraph langsmith langchain_google_genai langchain_community tavily-python graphviz langgraph.tools\n"
      ],
      "metadata": {
        "id": "yJXRL2rXkcrz"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('LANGCHAIN_API_KEY')\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"quickstart\"\n",
        "\n",
        "gemini_api_key = userdata.get('GEMINI_API_KEY')"
      ],
      "metadata": {
        "id": "zHtvydxWxGVp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    max_retries=2,\n",
        "    temperature=0.7,\n",
        "    max_tokens=200,\n",
        "    api_key=gemini_api_key\n",
        ")\n",
        "\n",
        "llm.invoke(\"greet me\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzeRUaHZuiUm",
        "outputId": "c022d4c4-9019-41eb-a6c7-e3e56ae9ccff",
        "collapsed": true
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Hello there!  How are you doing today?\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-4ee71d20-e7a8-4d91-adf2-7ca7d27b0ff2-0', usage_metadata={'input_tokens': 3, 'output_tokens': 11, 'total_tokens': 14, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iqtl_GuzkFb0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# One Section"
      ],
      "metadata": {
        "id": "Efi_bJLbkF9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain.prompts.chat import ChatPromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.tools import Tool\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "import os\n",
        "\n",
        "# Step 1: Set up API keys\n",
        "os.environ[\"GEMINI_API_KEY\"] = userdata.get('GEMINI_API_KEY')\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get(\"TAVILY_API_KEY\")\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('LANGCHAIN_API_KEY')\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"quickstart\"\n",
        "\n",
        "\n",
        "# Step 2: Set up SQLite Database\n",
        "def init_db():\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS chat_history (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            user_input TEXT NOT NULL,\n",
        "            bot_response TEXT NOT NULL,\n",
        "            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP\n",
        "        )\n",
        "    \"\"\")\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def save_to_db(user_input, bot_response):\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"INSERT INTO chat_history (user_input, bot_response) VALUES (?, ?)\", (user_input, bot_response))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def fetch_history():\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT * FROM chat_history ORDER BY timestamp DESC LIMIT 10\")\n",
        "    rows = cursor.fetchall()\n",
        "    conn.close()\n",
        "    return rows\n",
        "\n",
        "# New: Function to delete conversation by ID\n",
        "def delete_from_db(conversation_id):\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # First, check if the conversation exists\n",
        "    cursor.execute(\"SELECT * FROM chat_history WHERE id = ?\", (conversation_id,))\n",
        "    row = cursor.fetchone()\n",
        "    if row:\n",
        "        # Proceed with deletion if found\n",
        "        cursor.execute(\"DELETE FROM chat_history WHERE id = ?\", (conversation_id,))\n",
        "        conn.commit()\n",
        "        print(f\"Conversation with ID {conversation_id} has been deleted.\")\n",
        "    else:\n",
        "        print(f\"No conversation found with ID {conversation_id}.\")\n",
        "\n",
        "    conn.close()\n",
        "\n",
        "# New: Function to update a record by ID\n",
        "def update_record(conversation_id, new_user_input=None, new_bot_response=None):\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    if new_user_input:\n",
        "        cursor.execute(\"UPDATE chat_history SET user_input = ? WHERE id = ?\", (new_user_input, conversation_id))\n",
        "    if new_bot_response:\n",
        "        cursor.execute(\"UPDATE chat_history SET bot_response = ? WHERE id = ?\", (new_bot_response, conversation_id))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "# New: Function to fetch all records\n",
        "def fetch_all_history():\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT * FROM chat_history ORDER BY timestamp DESC\")\n",
        "    rows = cursor.fetchall()\n",
        "    conn.close()\n",
        "    return rows\n",
        "\n",
        "\n",
        "# Step 3: Set up Tavily search tool\n",
        "tavily_tool = TavilySearchResults(max_results=3)\n",
        "\n",
        "# Step 4: Define the conversation memory\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# Step 5: Define the LLM\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    max_retries=2,\n",
        "    temperature=0.7,\n",
        "    max_tokens=200,\n",
        "    api_key=gemini_api_key\n",
        ")\n",
        "\n",
        "# Step 6: Initialize tools\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"TavilySearch\",\n",
        "        func=tavily_tool.run,\n",
        "        description=\"Useful for answering questions requiring research or external data.\"\n",
        "    )\n",
        "]\n",
        "\n",
        "# Step 7: Create the conversational agent\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        "    memory=memory,\n",
        ")\n",
        "# Step 8: Implement the chatbot function with delete feature\n",
        "\n",
        "def chatbot():\n",
        "    print(\"ÀóÀèÀã ‚òÖ ÀéÀäÀó welcome to the Chatbot... Type 'exit', 'quit', 'q' to end the conversation.\\n\")\n",
        "    print(\"Type 'history' to view the last 10 conversations.\\n\")\n",
        "    print(\"Type 'delete <id>' to delete a conversation by ID.\\n\")\n",
        "    print(\"Type 'update <id> <new_user_input> <new_bot_response>' to update a conversation.\\n\")\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() in [\"exit\", \"quit\", \"q\"]:\n",
        "            print(\"ùê†ùê®ùê®ùêùùêõùê≤ùêû üëã...\")\n",
        "            break\n",
        "        elif user_input.lower() in [\"data\", \"history\", \"h\"]:\n",
        "            history = fetch_history()\n",
        "            if not history:\n",
        "                print(\"No history found.\")\n",
        "            else:\n",
        "                for idx, (id, user, bot, timestamp) in enumerate(history, 1):\n",
        "                    print(f\"{idx}. {timestamp} - You: {user} | Bot: {bot}\")\n",
        "        elif user_input.lower().startswith(\"delete\"):\n",
        "            try:\n",
        "                conversation_id = int(user_input.split()[1])\n",
        "                delete_from_db(conversation_id)\n",
        "                print(f\"Deleted conversation with ID {conversation_id}.\")\n",
        "            except (IndexError, ValueError):\n",
        "                print(\"Invalid format. Use 'delete <id>'.\")\n",
        "        elif user_input.lower().startswith(\"update\"):\n",
        "            try:\n",
        "                parts = user_input.split(maxsplit=3)\n",
        "                conversation_id = int(parts[1])\n",
        "                new_user_input = parts[2]\n",
        "                new_bot_response = parts[3]\n",
        "                update_record(conversation_id, new_user_input, new_bot_response)\n",
        "                print(f\"Updated conversation with ID {conversation_id}.\")\n",
        "            except (IndexError, ValueError):\n",
        "                print(\"Invalid format. Use 'update <id> <new_user_input> <new_bot_response>'.\")\n",
        "        else:\n",
        "            response = agent.run(user_input)\n",
        "            print(f\"Bot: {response}\")\n",
        "\n",
        "            # Save to SQLite database\n",
        "            save_to_db(user_input, response)\n",
        "\n",
        "# Step 9: Initialize and run the chatbot\n",
        "if __name__ == \"__main__\":\n",
        "    init_db()\n",
        "    chatbot()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Step 5: Create the conversational agent\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        "    memory=memory,\n",
        ")\n",
        "\n",
        "# Step 6: Define programming keywords\n",
        "CODING_KEYWORDS = [\n",
        "    \"code\", \"program\", \"debug\", \"compile\", \"script\", \"API\", \"function\", \"class\",\n",
        "    \"framework\", \"error\", \"syntax\", \"variable\", \"loop\", \"algorithm\", \"test\"\n",
        "]\n",
        "\n",
        "def is_coding_prompt(prompt):\n",
        "    \"\"\"Check if the prompt contains programming-related keywords.\"\"\"\n",
        "    return any(keyword.lower() in prompt.lower() for keyword in CODING_KEYWORDS)\n",
        "\n",
        "# Step 7: Workflow visualization with Graphviz\n",
        "workflow_graph = Digraph(\"Coding Chatbot Workflow\", format=\"png\")\n",
        "workflow_graph.attr(rankdir=\"LR\")\n",
        "workflow_graph.node(\"Start\", shape=\"ellipse\", style=\"filled\", color=\"lightblue\")\n",
        "workflow_graph.node(\"Filter Prompt\", shape=\"box\", style=\"filled\", color=\"lightgreen\")\n",
        "workflow_graph.node(\"Generate Code\", shape=\"box\", style=\"filled\", color=\"lightyellow\")\n",
        "workflow_graph.node(\"Save to DB\", shape=\"box\", style=\"filled\", color=\"orange\")\n",
        "workflow_graph.node(\"End\", shape=\"ellipse\", style=\"filled\", color=\"lightblue\")\n",
        "workflow_graph.edges([(\"Start\", \"Filter Prompt\"), (\"Filter Prompt\", \"Generate Code\"),\n",
        "                      (\"Generate Code\", \"Save to DB\"), (\"Save to DB\", \"End\")])\n",
        "\n",
        "def render_workflow():\n",
        "    \"\"\"Render and display the workflow graph.\"\"\"\n",
        "    workflow_graph.render(\"coding_chatbot_workflow\", view=True)\n",
        "\n",
        "# Step 8: Implement the chatbot function\n",
        "def chatbot():\n",
        "    print(\"Welcome to the Coding Chatbot! I assist with programming-related questions.\\n\")\n",
        "    print(\"Type 'exit' to end the conversation.\\n\")\n",
        "    print(\"Type 'history' to view the last 10 conversations.\\n\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() in [\"exit\", \"quit\", \"q\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            render_workflow()\n",
        "            break\n",
        "        elif user_input.lower() == \"history\":\n",
        "            history = fetch_history()\n",
        "            if not history:\n",
        "                print(\"No history found.\")\n",
        "            else:\n",
        "                for idx, (id, user, bot, timestamp) in enumerate(history, 1):\n",
        "                    print(f\"{idx}. {timestamp} - You: {user} | Bot: {bot}\")\n",
        "        else:\n",
        "            if is_coding_prompt(user_input):\n",
        "                try:\n",
        "                    response = agent.run(user_input)\n",
        "                    print(f\"Bot: {response}\")\n",
        "                    save_to_db(user_input, response)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error: {e}\")\n",
        "            else:\n",
        "                print(\"I'm sorry, I can only assist with programming-related questions.\")\n",
        "\n",
        "# Step 9: Initialize and run the chatbot\n",
        "if __name__ == \"__main__\":\n",
        "    init_db()\n",
        "    chatbot()"
      ],
      "metadata": {
        "id": "VqfNDY1WWHuq",
        "outputId": "f66fb71a-8787-41d0-d0c3-58f6d640753a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ÀóÀèÀã ‚òÖ ÀéÀäÀó welcome to the Chatbot... Type 'exit', 'quit', 'q' to end the conversation.\n",
            "\n",
            "Type 'history' to view the last 10 conversations.\n",
            "\n",
            "Type 'delete <id>' to delete a conversation by ID.\n",
            "\n",
            "Type 'update <id> <new_user_input> <new_bot_response>' to update a conversation.\n",
            "\n",
            "You: q\n",
            "ùê†ùê®ùê®ùêùùêõùê≤ùêû üëã...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WcsTp0NGkLEs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tow Section"
      ],
      "metadata": {
        "id": "xPfbDOZwkLl3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain.prompts.chat import ChatPromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.tools import Tool\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "import os\n",
        "\n",
        "# Step 0: Set up API keys\n",
        "os.environ[\"GEMINI_API_KEY\"] = userdata.get('GEMINI_API_KEY')\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get(\"TAVILY_API_KEY\")\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('LANGCHAIN_API_KEY')\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"quickstart\"\n",
        "\n",
        "# Step 1: Set up SQLite Database\n",
        "def init_db():\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS chat_history (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            user_input TEXT NOT NULL,\n",
        "            bot_response TEXT NOT NULL,\n",
        "            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP\n",
        "        )\n",
        "    \"\"\")\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def save_to_db(user_input, bot_response):\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"INSERT INTO chat_history (user_input, bot_response) VALUES (?, ?)\", (user_input, bot_response))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def fetch_history():\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT * FROM chat_history ORDER BY timestamp DESC LIMIT 10\")\n",
        "    rows = cursor.fetchall()\n",
        "    conn.close()\n",
        "    return rows\n",
        "\n",
        "# New: Function to delete a record by ID\n",
        "def delete_from_db(conversation_id):\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"DELETE FROM chat_history WHERE id = ?\", (conversation_id,))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "# New: Function to update a record by ID\n",
        "def update_record(conversation_id, new_user_input=None, new_bot_response=None):\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    if new_user_input:\n",
        "        cursor.execute(\"UPDATE chat_history SET user_input = ? WHERE id = ?\", (new_user_input, conversation_id))\n",
        "    if new_bot_response:\n",
        "        cursor.execute(\"UPDATE chat_history SET bot_response = ? WHERE id = ?\", (new_bot_response, conversation_id))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "# New: Function to fetch all records\n",
        "def fetch_all_history():\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT * FROM chat_history ORDER BY timestamp DESC\")\n",
        "    rows = cursor.fetchall()\n",
        "    conn.close()\n",
        "    return rows\n",
        "\n",
        "# Step 2: Set up Tavily search tool\n",
        "tavily_tool = TavilySearchResults(max_results=3)\n",
        "\n",
        "# Step 3: Define the conversation memory\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# Step 4: Define the LLM\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    max_retries=2,\n",
        "    temperature=0.7,\n",
        "    max_tokens=200,\n",
        "    api_key=gemini_api_key\n",
        ")\n",
        "\n",
        "\n",
        "# Step 5: Initialize tools\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"TavilySearch\",\n",
        "        func=tavily_tool.run,\n",
        "        description=\"Useful for answering questions requiring research or external data.\"\n",
        "    )\n",
        "]\n",
        "\n",
        "# Step 6: Create the conversational agent\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        "    memory=memory,\n",
        ")\n",
        "\n",
        "# Step 7: Implement the chatbot function\n",
        "def chatbot():\n",
        "    print(\"Welcome to the Chatbot! Type 'exit', 'quit', 'q' to end the conversation.\\n\")\n",
        "    print(\"Type 'history' to view the last 10 conversations.\\n\")\n",
        "    print(\"Type 'delete <id>' to delete a conversation by ID.\\n\")\n",
        "    print(\"Type 'update <id> <new_user_input> <new_bot_response>' to update a conversation.\\n\")\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() in [\"exit\", \"quit\", \"q\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "        elif user_input.lower() in [\"data\", \"history\", \"h\"]:\n",
        "            history = fetch_history()\n",
        "            if not history:\n",
        "                print(\"No history found.\")\n",
        "            else:\n",
        "                for idx, (id, user, bot, timestamp) in enumerate(history, 1):\n",
        "                    print(f\"{idx}. {timestamp} - You: {user} | Bot: {bot}\")\n",
        "        elif user_input.lower().startswith(\"delete\"):\n",
        "            try:\n",
        "                conversation_id = int(user_input.split()[1])\n",
        "                delete_from_db(conversation_id)\n",
        "                print(f\"Deleted conversation with ID {conversation_id}.\")\n",
        "            except (IndexError, ValueError):\n",
        "                print(\"Invalid format. Use 'delete <id>'.\")\n",
        "        elif user_input.lower().startswith(\"update\"):\n",
        "            try:\n",
        "                parts = user_input.split(maxsplit=3)\n",
        "                conversation_id = int(parts[1])\n",
        "                new_user_input = parts[2]\n",
        "                new_bot_response = parts[3]\n",
        "                update_record(conversation_id, new_user_input, new_bot_response)\n",
        "                print(f\"Updated conversation with ID {conversation_id}.\")\n",
        "            except (IndexError, ValueError):\n",
        "                print(\"Invalid format. Use 'update <id> <new_user_input> <new_bot_response>'.\")\n",
        "        else:\n",
        "            response = agent.run(user_input)\n",
        "            print(f\"Bot: {response}\")\n",
        "            save_to_db(user_input, response)\n",
        "\n",
        "# Step 8: Initialize and run the chatbot\n",
        "if __name__ == \"__main__\":\n",
        "    init_db()\n",
        "    chatbot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYkJ0HUikLCE",
        "outputId": "6b37e4de-d1e8-4c45-ddb6-66a6ee5aa655"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Chatbot! Type 'exit', 'quit', 'q' to end the conversation.\n",
            "\n",
            "Type 'history' to view the last 10 conversations.\n",
            "\n",
            "Type 'delete <id>' to delete a conversation by ID.\n",
            "\n",
            "Type 'update <id> <new_user_input> <new_bot_response>' to update a conversation.\n",
            "\n",
            "You: q\n",
            "Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nCpKmypqkPys"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Three Section"
      ],
      "metadata": {
        "id": "-rNxNC8akQEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain.prompts.chat import ChatPromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.tools import Tool\n",
        "from langchain.agents import initialize_agent, Tool, AgentType\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "\n",
        "# Step 1: Set up SQLite Database\n",
        "def init_db():\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS chat_history (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            user_input TEXT NOT NULL,\n",
        "            bot_response TEXT NOT NULL,\n",
        "            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP\n",
        "        )\n",
        "    \"\"\")\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def save_to_db(user_input, bot_response):\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"INSERT INTO chat_history (user_input, bot_response) VALUES (?, ?)\", (user_input, bot_response))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def fetch_history():\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT * FROM chat_history ORDER BY timestamp DESC LIMIT 10\")\n",
        "    rows = cursor.fetchall()\n",
        "    conn.close()\n",
        "    return rows\n",
        "\n",
        "# Step 2: Set up Tavily search tool\n",
        "tavily_tool = TavilySearchResults(max_results=3)\n",
        "\n",
        "# Step 3: Define the conversation memory\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# Step 4: Define the LLM\n",
        "\n",
        "\n",
        "# Step 5: Initialize tools\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"TavilySearch\",\n",
        "        func=tavily_tool.run,\n",
        "        description=\"Useful for answering questions requiring research or external data.\"\n",
        "    )\n",
        "]\n",
        "\n",
        "# Step 6: Create the conversational agent\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        "    memory=memory,\n",
        ")\n",
        "\n",
        "# Step 7: Implement the chatbot function\n",
        "def chatbot():\n",
        "    print(\"Welcome to the Chatbot! Type 'exit' to end the conversation.\\n\")\n",
        "    print(\"Type 'history' to view the last 10 conversations.\\n\")\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "        elif user_input.lower() == \"history\":\n",
        "            history = fetch_history()\n",
        "            if not history:\n",
        "                print(\"No history found.\")\n",
        "            else:\n",
        "                for idx, (id, user, bot, timestamp) in enumerate(history, 1):\n",
        "                    print(f\"{idx}. {timestamp} - You: {user} | Bot: {bot}\")\n",
        "        else:\n",
        "            response = agent.run(user_input)\n",
        "            print(f\"Bot: {response}\")\n",
        "            save_to_db(user_input, response)\n",
        "\n",
        "# Step 8: Initialize and run the chatbot\n",
        "if __name__ == \"__main__\":\n",
        "    init_db()\n",
        "    chatbot()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVMNi2srmBC8",
        "outputId": "8305eb3d-79ef-4cfd-b473-6d9c732f2525",
        "collapsed": true
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Chatbot! Type 'exit' to end the conversation.\n",
            "\n",
            "Type 'history' to view the last 10 conversations.\n",
            "\n",
            "You: q\n",
            "Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "N-zR6W5AkV9j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Four Section"
      ],
      "metadata": {
        "id": "SlV3oRBjkWO9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain.prompts.chat import ChatPromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.tools import Tool\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "# Step 1: Set up SQLite Database\n",
        "def init_db():\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS chat_history (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            user_input TEXT NOT NULL,\n",
        "            bot_response TEXT NOT NULL,\n",
        "            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP\n",
        "        )\n",
        "    \"\"\")\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def save_to_db(user_input, bot_response):\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"INSERT INTO chat_history (user_input, bot_response) VALUES (?, ?)\", (user_input, bot_response))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def fetch_history():\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT * FROM chat_history ORDER BY timestamp DESC LIMIT 10\")\n",
        "    rows = cursor.fetchall()\n",
        "    conn.close()\n",
        "    return rows\n",
        "\n",
        "# New: Function to delete a record by ID\n",
        "def delete_from_db(conversation_id):\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"DELETE FROM chat_history WHERE id = ?\", (conversation_id,))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "# New: Function to update a record by ID\n",
        "def update_record(conversation_id, new_user_input=None, new_bot_response=None):\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    if new_user_input:\n",
        "        cursor.execute(\"UPDATE chat_history SET user_input = ? WHERE id = ?\", (new_user_input, conversation_id))\n",
        "    if new_bot_response:\n",
        "        cursor.execute(\"UPDATE chat_history SET bot_response = ? WHERE id = ?\", (new_bot_response, conversation_id))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "# New: Function to fetch all records\n",
        "def fetch_all_history():\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT * FROM chat_history ORDER BY timestamp DESC\")\n",
        "    rows = cursor.fetchall()\n",
        "    conn.close()\n",
        "    return rows\n",
        "\n",
        "# Step 2: Set up Tavily search tool\n",
        "tavily_tool = TavilySearchResults(max_results=3)\n",
        "\n",
        "# Step 3: Define the conversation memory\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# Step 4: Define the LLM\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    max_retries=2,\n",
        "    temperature=0.7,\n",
        "    max_tokens=200,\n",
        "    api_key=gemini_api_key\n",
        ")\n",
        "\n",
        "# Step 5: Initialize tools\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"TavilySearch\",\n",
        "        func=tavily_tool.run,\n",
        "        description=\"Useful for answering questions requiring research or external data.\"\n",
        "    )\n",
        "]\n",
        "\n",
        "# Step 6: Create the conversational agent\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        "    memory=memory,\n",
        ")\n",
        "\n",
        "# Step 7: Implement the chatbot function\n",
        "def chatbot():\n",
        "    print(\"Welcome to the Chatbot! Type 'exit' to end the conversation.\\n\")\n",
        "    print(\"Type 'history' to view the last 10 conversations.\\n\")\n",
        "    print(\"Type 'delete <id>' to delete a conversation by ID.\\n\")\n",
        "    print(\"Type 'update <id> <new_user_input> <new_bot_response>' to update a conversation.\\n\")\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == \"exit\":\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "        elif user_input.lower() == \"history\":\n",
        "            history = fetch_history()\n",
        "            if not history:\n",
        "                print(\"No history found.\")\n",
        "            else:\n",
        "                for idx, (id, user, bot, timestamp) in enumerate(history, 1):\n",
        "                    print(f\"{idx}. {timestamp} - You: {user} | Bot: {bot}\")\n",
        "        elif user_input.lower().startswith(\"delete\"):\n",
        "            try:\n",
        "                conversation_id = int(user_input.split()[1])\n",
        "                delete_from_db(conversation_id)\n",
        "                print(f\"Deleted conversation with ID {conversation_id}.\")\n",
        "            except (IndexError, ValueError):\n",
        "                print(\"Invalid format. Use 'delete <id>'.\")\n",
        "        elif user_input.lower().startswith(\"update\"):\n",
        "            try:\n",
        "                parts = user_input.split(maxsplit=3)\n",
        "                conversation_id = int(parts[1])\n",
        "                new_user_input = parts[2]\n",
        "                new_bot_response = parts[3]\n",
        "                update_record(conversation_id, new_user_input, new_bot_response)\n",
        "                print(f\"Updated conversation with ID {conversation_id}.\")\n",
        "            except (IndexError, ValueError):\n",
        "                print(\"Invalid format. Use 'update <id> <new_user_input> <new_bot_response>'.\")\n",
        "        else:\n",
        "            response = agent.run(user_input)\n",
        "            print(f\"Bot: {response}\")\n",
        "            save_to_db(user_input, response)\n",
        "\n",
        "# Step 8: Initialize and run the chatbot\n",
        "if __name__ == \"__main__\":\n",
        "    init_db()\n",
        "    chatbot()\n"
      ],
      "metadata": {
        "id": "71gpPtiYMn1E",
        "outputId": "e2c4e943-5a94-4def-8c4b-c63ac6888320",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Chatbot! Type 'exit' to end the conversation.\n",
            "\n",
            "Type 'history' to view the last 10 conversations.\n",
            "\n",
            "Type 'delete <id>' to delete a conversation by ID.\n",
            "\n",
            "Type 'update <id> <new_user_input> <new_bot_response>' to update a conversation.\n",
            "\n",
            "You: q\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: The question \"q\" is too vague to answer.  I need a more specific question.\n",
            "Final Answer: I need a more specific question to answer.\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Bot: I need a more specific question to answer.\n",
            "You: q\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised InternalServerError: 500 Unable to submit request because the service is temporarily unavailable..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mThought: The question \"q\" is too vague to answer.  I need a more specific question.\n",
            "Final Answer: I need a more specific question to answer.\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Bot: I need a more specific question to answer.\n",
            "You: exit\n",
            "Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Cq1E29EokcY7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Five Section"
      ],
      "metadata": {
        "id": "p9jULmltkcj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain.prompts.chat import ChatPromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.tools import Tool\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "# Step 1: Set up SQLite Database\n",
        "def init_db():\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS chat_history (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            user_input TEXT NOT NULL,\n",
        "            bot_response TEXT NOT NULL,\n",
        "            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP\n",
        "        )\n",
        "    \"\"\")\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def save_to_db(user_input, bot_response):\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"INSERT INTO chat_history (user_input, bot_response) VALUES (?, ?)\", (user_input, bot_response))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def fetch_history():\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT * FROM chat_history ORDER BY timestamp DESC LIMIT 10\")\n",
        "    rows = cursor.fetchall()\n",
        "    conn.close()\n",
        "    return rows\n",
        "\n",
        "# Step 2: Set up Tavily search tool\n",
        "tavily_tool = TavilySearchResults(max_results=3)\n",
        "\n",
        "# Step 3: Define the conversation memory\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# Step 4: Define the LLM\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    max_retries=2,\n",
        "    temperature=0.7,\n",
        "    max_tokens=200,\n",
        "    api_key=gemini_api_key\n",
        ")\n",
        "\n",
        "# Step 5: Initialize tools\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"TavilySearch\",\n",
        "        func=tavily_tool.run,\n",
        "        description=\"Useful for answering questions requiring research or external data.\"\n",
        "    )\n",
        "]\n",
        "\n",
        "# Step 6: Create the conversational agent\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        "    memory=memory,\n",
        ")\n",
        "\n",
        "# Step 7: Define medical keywords and filtering function\n",
        "MEDICAL_KEYWORDS = [\n",
        "    \"medicine\", \"symptoms\", \"diagnosis\", \"treatment\", \"disease\", \"doctor\",\n",
        "    \"hospital\", \"health\", \"surgery\", \"therapy\", \"infection\", \"pharmacy\", \"drug\"\n",
        "]\n",
        "\n",
        "def is_medical_prompt(prompt):\n",
        "    \"\"\"Check if the prompt contains medical-related keywords.\"\"\"\n",
        "    return any(keyword.lower() in prompt.lower() for keyword in MEDICAL_KEYWORDS)\n",
        "\n",
        "# Step 8: Implement the chatbot function\n",
        "def chatbot():\n",
        "    print(\"Welcome to the Medical Chatbot! I only answer medical-related questions.\\n\")\n",
        "    print(\"Type 'exit' to end the conversation.\\n\")\n",
        "    print(\"Type 'history' to view the last 10 conversations.\\n\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() in [\"exit\", \"quit\", \"q\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "        elif user_input.lower() == \"history\":\n",
        "            history = fetch_history()\n",
        "            if not history:\n",
        "                print(\"No history found.\")\n",
        "            else:\n",
        "                for idx, (id, user, bot, timestamp) in enumerate(history, 1):\n",
        "                    print(f\"{idx}. {timestamp} - You: {user} | Bot: {bot}\")\n",
        "        else:\n",
        "            if is_medical_prompt(user_input):\n",
        "                response = agent.run(user_input)\n",
        "                print(f\"Bot: {response}\")\n",
        "                save_to_db(user_input, response)\n",
        "            else:\n",
        "                print(\"I'm sorry, I can only assist with medical-related questions.\")\n",
        "\n",
        "# Step 9: Initialize and run the chatbot\n",
        "if __name__ == \"__main__\":\n",
        "    init_db()\n",
        "    chatbot()\n"
      ],
      "metadata": {
        "id": "d76mv22Vtxr6",
        "collapsed": true,
        "outputId": "57370158-1ce7-46e7-e290-4ddc7e01e134",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Medical Chatbot! I only answer medical-related questions.\n",
            "\n",
            "Type 'exit' to end the conversation.\n",
            "\n",
            "Type 'history' to view the last 10 conversations.\n",
            "\n",
            "You: exit\n",
            "Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rV7XXgVgkiYL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Six Section"
      ],
      "metadata": {
        "id": "FIoy7y5skivF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain.prompts.chat import ChatPromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.tools import Tool\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from graphviz import Digraph\n",
        "\n",
        "# Step 1: Set up SQLite Database\n",
        "def init_db():\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS chat_history (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            user_input TEXT NOT NULL,\n",
        "            bot_response TEXT NOT NULL,\n",
        "            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP\n",
        "        )\n",
        "    \"\"\")\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def save_to_db(user_input, bot_response):\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"INSERT INTO chat_history (user_input, bot_response) VALUES (?, ?)\", (user_input, bot_response))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "# Step 2: Set up Tavily search tool\n",
        "tavily_tool = TavilySearchResults(max_results=3)\n",
        "\n",
        "# Step 3: Define the conversation memory\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# Step 4: Define the LLM\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    max_retries=2,\n",
        "    temperature=0.7,\n",
        "    max_tokens=200,\n",
        "    api_key=gemini_api_key\n",
        ")\n",
        "\n",
        "# Step 5: Initialize tools\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"TavilySearch\",\n",
        "        func=tavily_tool.run,\n",
        "        description=\"Useful for answering questions requiring research or external data.\"\n",
        "    )\n",
        "]\n",
        "\n",
        "# Step 6: Create the conversational agent\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        "    memory=memory,\n",
        ")\n",
        "\n",
        "# Step 7: Define medical keywords and filtering function\n",
        "MEDICAL_KEYWORDS = [\n",
        "    \"medicine\", \"symptoms\", \"diagnosis\", \"treatment\", \"disease\", \"doctor\",\n",
        "    \"hospital\", \"health\", \"surgery\", \"therapy\", \"infection\", \"pharmacy\", \"drug\"\n",
        "]\n",
        "\n",
        "def is_medical_prompt(prompt):\n",
        "    \"\"\"Check if the prompt contains medical-related keywords.\"\"\"\n",
        "    return any(keyword.lower() in prompt.lower() for keyword in MEDICAL_KEYWORDS)\n",
        "\n",
        "# Step 8: Initialize workflow visualization\n",
        "workflow_graph = Digraph(\"Chatbot Workflow\", format=\"png\")\n",
        "workflow_graph.attr(rankdir=\"LR\")  # Set direction of flow\n",
        "workflow_graph.node(\"Start\", shape=\"ellipse\", style=\"filled\", color=\"lightblue\")\n",
        "workflow_graph.node(\"Filter Prompt\", shape=\"box\", style=\"filled\", color=\"lightgreen\")\n",
        "workflow_graph.node(\"Generate Response\", shape=\"box\", style=\"filled\", color=\"lightyellow\")\n",
        "workflow_graph.node(\"Save to DB\", shape=\"box\", style=\"filled\", color=\"orange\")\n",
        "workflow_graph.node(\"End\", shape=\"ellipse\", style=\"filled\", color=\"lightblue\")\n",
        "workflow_graph.edges([(\"Start\", \"Filter Prompt\"), (\"Filter Prompt\", \"Generate Response\"),\n",
        "                      (\"Generate Response\", \"Save to DB\"), (\"Save to DB\", \"End\")])\n",
        "\n",
        "def render_workflow():\n",
        "    \"\"\"Render and display the workflow graph.\"\"\"\n",
        "    workflow_graph.render(\"chatbot_workflow\", view=True)\n",
        "\n",
        "# Step 9: Implement the chatbot function\n",
        "def chatbot():\n",
        "    print(\"Welcome to the Medical Chatbot! I only answer medical-related questions.\\n\")\n",
        "    print(\"Type 'exit' to end the conversation.\\n\")\n",
        "    print(\"Type 'history' to view the last 10 conversations.\\n\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() in [\"exit\", \"quit\", \"q\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            render_workflow()  # Display workflow graph at the end\n",
        "            break\n",
        "        elif user_input.lower() == \"history\":\n",
        "            history = fetch_history()\n",
        "            if not history:\n",
        "                print(\"No history found.\")\n",
        "            else:\n",
        "                for idx, (id, user, bot, timestamp) in enumerate(history, 1):\n",
        "                    print(f\"{idx}. {timestamp} - You: {user} | Bot: {bot}\")\n",
        "        else:\n",
        "            workflow_graph.node(user_input, shape=\"ellipse\", style=\"dashed\", color=\"grey\")\n",
        "            workflow_graph.edge(\"Start\", user_input)\n",
        "\n",
        "            if is_medical_prompt(user_input):\n",
        "                workflow_graph.edge(user_input, \"Filter Prompt\")\n",
        "                response = agent.run(user_input)\n",
        "                workflow_graph.edge(\"Filter Prompt\", \"Generate Response\")\n",
        "                print(f\"Bot: {response}\")\n",
        "                save_to_db(user_input, response)\n",
        "                workflow_graph.edge(\"Generate Response\", \"Save to DB\")\n",
        "            else:\n",
        "                print(\"I'm sorry, I can only assist with medical-related questions.\")\n",
        "                workflow_graph.edge(user_input, \"Filter Prompt\")\n",
        "                workflow_graph.edge(\"Filter Prompt\", \"End\")\n",
        "\n",
        "# Step 10: Initialize and run the chatbot\n",
        "if __name__ == \"__main__\":\n",
        "    init_db()\n",
        "    chatbot()\n"
      ],
      "metadata": {
        "id": "bm4RgaLBvrBt",
        "outputId": "87f86145-078a-4dd4-dcda-48a5596acb46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Medical Chatbot! I only answer medical-related questions.\n",
            "\n",
            "Type 'exit' to end the conversation.\n",
            "\n",
            "Type 'history' to view the last 10 conversations.\n",
            "\n",
            "You: exit\n",
            "Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "F2nGKJ52j-hm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Seven Section"
      ],
      "metadata": {
        "id": "cuhF-AGjj_C3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain.prompts.chat import ChatPromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.tools import Tool\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from graphviz import Digraph\n",
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# Step 1: Set up SQLite Database\n",
        "def init_db():\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS chat_history (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            user_input TEXT NOT NULL,\n",
        "            bot_response TEXT NOT NULL,\n",
        "            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP\n",
        "        )\n",
        "    \"\"\")\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def save_to_db(user_input, bot_response):\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"INSERT INTO chat_history (user_input, bot_response) VALUES (?, ?)\", (user_input, bot_response))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def fetch_history():\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT * FROM chat_history ORDER BY timestamp DESC LIMIT 10\")\n",
        "    rows = cursor.fetchall()\n",
        "    conn.close()\n",
        "    return rows\n",
        "\n",
        "# Step 2: Set up Tavily search tool\n",
        "tavily_tool = TavilySearchResults(max_results=3)\n",
        "\n",
        "# Step 3: Define the conversation memory\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# Step 4: Define the LLM\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    max_retries=2,\n",
        "    temperature=0.7,\n",
        "    max_tokens=200,\n",
        "    api_key=gemini_api_key\n",
        ")\n",
        "\n",
        "# Step 5: Initialize tools\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"TavilySearch\",\n",
        "        func=tavily_tool.run,\n",
        "        description=\"Useful for answering questions requiring research or external data.\"\n",
        "    )\n",
        "]\n",
        "\n",
        "# Step 6: Create the conversational agent\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        "    memory=memory,\n",
        ")\n",
        "\n",
        "# Step 7: Define medical keywords and filtering function\n",
        "MEDICAL_KEYWORDS = [\n",
        "    \"medicine\", \"symptoms\", \"diagnosis\", \"treatment\", \"disease\", \"doctor\",\n",
        "    \"hospital\", \"health\", \"surgery\", \"therapy\", \"infection\", \"pharmacy\", \"drug\"\n",
        "]\n",
        "\n",
        "def is_medical_prompt(prompt):\n",
        "    \"\"\"Check if the prompt contains medical-related keywords.\"\"\"\n",
        "    return any(keyword.lower() in prompt.lower() for keyword in MEDICAL_KEYWORDS)\n",
        "\n",
        "# Step 8: Initialize workflow visualization with Graphviz\n",
        "workflow_graph = Digraph(\"Chatbot Workflow\", format=\"png\")\n",
        "workflow_graph.attr(rankdir=\"LR\")\n",
        "workflow_graph.node(\"Start\", shape=\"ellipse\", style=\"filled\", color=\"lightblue\")\n",
        "workflow_graph.node(\"Filter Prompt\", shape=\"box\", style=\"filled\", color=\"lightgreen\")\n",
        "workflow_graph.node(\"Generate Response\", shape=\"box\", style=\"filled\", color=\"lightyellow\")\n",
        "workflow_graph.node(\"Save to DB\", shape=\"box\", style=\"filled\", color=\"orange\")\n",
        "workflow_graph.node(\"End\", shape=\"ellipse\", style=\"filled\", color=\"lightblue\")\n",
        "workflow_graph.edges([(\"Start\", \"Filter Prompt\"), (\"Filter Prompt\", \"Generate Response\"),\n",
        "                      (\"Generate Response\", \"Save to DB\"), (\"Save to DB\", \"End\")])\n",
        "\n",
        "def render_workflow():\n",
        "    \"\"\"Render and display the workflow graph.\"\"\"\n",
        "    workflow_graph.render(\"chatbot_workflow\", view=True)\n",
        "\n",
        "# Step 9: Chatbot logic with state graph integration\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "def chatbot_logic(state: State):\n",
        "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
        "\n",
        "graph_builder.add_node(\"chatbot_logic\", chatbot_logic)\n",
        "graph_builder.add_edge(START, \"chatbot_logic\")\n",
        "graph_builder.add_edge(\"chatbot_logic\", END)\n",
        "graph = graph_builder.compile()\n",
        "\n",
        "# Step 10: Chatbot Execution Function\n",
        "def chatbot():\n",
        "    print(\"Welcome to the Medical Chatbot! I only answer medical-related questions.\\n\")\n",
        "    print(\"Type 'exit' to end the conversation.\\n\")\n",
        "    print(\"Type 'history' to view the last 10 conversations.\\n\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() in [\"exit\", \"quit\", \"q\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            render_workflow()\n",
        "            try:\n",
        "                display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "            except Exception:\n",
        "                print(\"Graph rendering failed.\")\n",
        "            break\n",
        "        elif user_input.lower() == \"history\":\n",
        "            history = fetch_history()\n",
        "            if not history:\n",
        "                print(\"No history found.\")\n",
        "            else:\n",
        "                for idx, (id, user, bot, timestamp) in enumerate(history, 1):\n",
        "                    print(f\"{idx}. {timestamp} - You: {user} | Bot: {bot}\")\n",
        "        else:\n",
        "            workflow_graph.node(user_input, shape=\"ellipse\", style=\"dashed\", color=\"grey\")\n",
        "            workflow_graph.edge(\"Start\", user_input)\n",
        "\n",
        "            if is_medical_prompt(user_input):\n",
        "                workflow_graph.edge(user_input, \"Filter Prompt\")\n",
        "                response = agent.run(user_input)\n",
        "                workflow_graph.edge(\"Filter Prompt\", \"Generate Response\")\n",
        "                print(f\"Bot: {response}\")\n",
        "                save_to_db(user_input, response)\n",
        "                workflow_graph.edge(\"Generate Response\", \"Save to DB\")\n",
        "            else:\n",
        "                print(\"I'm sorry, I can only assist with medical-related questions.\")\n",
        "                workflow_graph.edge(user_input, \"Filter Prompt\")\n",
        "                workflow_graph.edge(\"Filter Prompt\", \"End\")\n",
        "\n",
        "# Step 11: Initialize and run the chatbot\n",
        "if __name__ == \"__main__\":\n",
        "    init_db()\n",
        "    chatbot()\n"
      ],
      "metadata": {
        "id": "bkxZ_43wynOl",
        "outputId": "f04ef36e-ff8a-4973-f61d-c0ea86c71f13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "collapsed": true
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Medical Chatbot! I only answer medical-related questions.\n",
            "\n",
            "Type 'exit' to end the conversation.\n",
            "\n",
            "Type 'history' to view the last 10 conversations.\n",
            "\n",
            "You: exit\n",
            "Goodbye!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vKm7QF_zuCna"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Eight Section"
      ],
      "metadata": {
        "id": "DjH_1uSkuDFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U  langgraph_tools"
      ],
      "metadata": {
        "id": "7fvHylvMymJm",
        "outputId": "3117d9ee-0878-4122-9b58-66823348fb97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement langgraph_tools (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for langgraph_tools\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain.prompts.chat import ChatPromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.tools import Tool\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from graphviz import Digraph\n",
        "\n",
        "# Step 1: Set up SQLite Database\n",
        "def init_db():\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS chat_history (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            user_input TEXT NOT NULL,\n",
        "            bot_response TEXT NOT NULL,\n",
        "            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP\n",
        "        )\n",
        "    \"\"\")\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def save_to_db(user_input, bot_response):\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"INSERT INTO chat_history (user_input, bot_response) VALUES (?, ?)\", (user_input, bot_response))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def fetch_history():\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT * FROM chat_history ORDER BY timestamp DESC LIMIT 10\")\n",
        "    rows = cursor.fetchall()\n",
        "    conn.close()\n",
        "    return rows\n",
        "\n",
        "# Step 2: Set up Tavily search tool\n",
        "tavily_tool = TavilySearchResults(max_results=3)\n",
        "\n",
        "# Step 3: Define the conversation memory\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# Step 4: Define the LLM\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    max_retries=2,\n",
        "    temperature=0.7,\n",
        "    max_tokens=200,\n",
        "    api_key=gemini_api_key\n",
        ")\n",
        "\n",
        "\n",
        "# Step 5: Initialize tools\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"TavilySearch\",\n",
        "        func=tavily_tool.run,\n",
        "        description=\"Useful for answering coding-related questions requiring external data.\"\n",
        "    )\n",
        "]\n",
        "\n",
        "# Step 6: Create the conversational agent\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        "    memory=memory,\n",
        ")\n",
        "\n",
        "# Step 7: Define coding keywords and filtering function\n",
        "CODING_KEYWORDS = [\n",
        "    \"code\", \"program\", \"script\", \"Python\", \"JavaScript\", \"HTML\", \"CSS\", \"Java\",\n",
        "    \"C++\", \"debug\", \"function\", \"class\", \"loop\", \"algorithm\", \"database\", \"API\", \"framework\"\n",
        "]\n",
        "\n",
        "def is_coding_prompt(prompt):\n",
        "    \"\"\"Check if the prompt contains coding-related keywords.\"\"\"\n",
        "    return any(keyword.lower() in prompt.lower() for keyword in CODING_KEYWORDS)\n",
        "\n",
        "# Step 8: Initialize workflow visualization\n",
        "workflow_graph = Digraph(\"Chatbot Workflow\", format=\"png\")\n",
        "workflow_graph.attr(rankdir=\"LR\")\n",
        "workflow_graph.node(\"Start\", shape=\"ellipse\", style=\"filled\", color=\"lightblue\")\n",
        "workflow_graph.node(\"Filter Prompt\", shape=\"box\", style=\"filled\", color=\"lightgreen\")\n",
        "workflow_graph.node(\"Generate Response\", shape=\"box\", style=\"filled\", color=\"lightyellow\")\n",
        "workflow_graph.node(\"Save to DB\", shape=\"box\", style=\"filled\", color=\"orange\")\n",
        "workflow_graph.node(\"End\", shape=\"ellipse\", style=\"filled\", color=\"lightblue\")\n",
        "workflow_graph.edges([(\"Start\", \"Filter Prompt\"), (\"Filter Prompt\", \"Generate Response\"),\n",
        "                      (\"Generate Response\", \"Save to DB\"), (\"Save to DB\", \"End\")])\n",
        "\n",
        "def render_workflow():\n",
        "    \"\"\"Render and display the workflow graph.\"\"\"\n",
        "    workflow_graph.render(\"chatbot_workflow\", view=True)\n",
        "\n",
        "# Step 9: Implement the chatbot function\n",
        "def chatbot():\n",
        "    print(\"Welcome to the Coding Chatbot! I only assist with coding-related queries.\\n\")\n",
        "    print(\"Type 'exit' to end the conversation.\\n\")\n",
        "    print(\"Type 'history' to view the last 10 conversations.\\n\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() in [\"exit\", \"quit\", \"q\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            render_workflow()  # Display workflow graph at the end\n",
        "            break\n",
        "        elif user_input.lower() == \"history\":\n",
        "            history = fetch_history()\n",
        "            if not history:\n",
        "                print(\"No history found.\")\n",
        "            else:\n",
        "                for idx, (id, user, bot, timestamp) in enumerate(history, 1):\n",
        "                    print(f\"{idx}. {timestamp} - You: {user} | Bot: {bot}\")\n",
        "        else:\n",
        "            workflow_graph.node(user_input, shape=\"ellipse\", style=\"dashed\", color=\"grey\")\n",
        "            workflow_graph.edge(\"Start\", user_input)\n",
        "\n",
        "            if is_coding_prompt(user_input):\n",
        "                workflow_graph.edge(user_input, \"Filter Prompt\")\n",
        "                response = agent.run(user_input)\n",
        "                workflow_graph.edge(\"Filter Prompt\", \"Generate Response\")\n",
        "                print(f\"Bot: {response}\")\n",
        "                save_to_db(user_input, response)\n",
        "                workflow_graph.edge(\"Generate Response\", \"Save to DB\")\n",
        "            else:\n",
        "                print(\"I'm sorry, I can only assist with coding-related questions.\")\n",
        "                workflow_graph.edge(user_input, \"Filter Prompt\")\n",
        "                workflow_graph.edge(\"Filter Prompt\", \"End\")\n",
        "\n",
        "# Step 10: Initialize and run the chatbot\n",
        "if __name__ == \"__main__\":\n",
        "    init_db()\n",
        "    chatbot()\n"
      ],
      "metadata": {
        "id": "KCRSSGIyuJNL",
        "outputId": "c5f5ee34-e9bb-4330-bd0d-ddd9ced0d6c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Coding Chatbot! I only assist with coding-related queries.\n",
            "\n",
            "Type 'exit' to end the conversation.\n",
            "\n",
            "Type 'history' to view the last 10 conversations.\n",
            "\n",
            "You: Can you generate a navbar\n",
            "I'm sorry, I can only assist with coding-related questions.\n",
            "You: exit\n",
            "Goodbye!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "python.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "google": {
      "image_path": "/static/site-assets/images/docs/logo-python.svg",
      "keywords": [
        "examples",
        "gemini",
        "beginner",
        "googleai",
        "quickstart",
        "python",
        "text",
        "chat",
        "vision",
        "embed"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}