{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -U langgraph langsmith langchain_google_genai langchain_community tavily-python graphviz\n"
      ],
      "metadata": {
        "id": "yJXRL2rXkcrz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('LANGCHAIN_API_KEY')\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"quickstart\"\n",
        "\n",
        "gemini_api_key = userdata.get('GEMINI_API_KEY')"
      ],
      "metadata": {
        "id": "zHtvydxWxGVp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    max_retries=2,\n",
        "    temperature=0.7,\n",
        "    max_tokens=200,\n",
        "    api_key=gemini_api_key\n",
        ")\n",
        "\n",
        "llm.invoke(\"greet me\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzeRUaHZuiUm",
        "outputId": "bfbba110-dad5-45d2-f3ba-f12acbf2195a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Hello there!\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-18155d86-3f7f-4f27-8e8b-9e622ec31f15-0', usage_metadata={'input_tokens': 3, 'output_tokens': 4, 'total_tokens': 7, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain.prompts.chat import ChatPromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.tools import Tool\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "# Step 1: Set up SQLite Database\n",
        "def init_db():\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS chat_history (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            user_input TEXT NOT NULL,\n",
        "            bot_response TEXT NOT NULL,\n",
        "            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP\n",
        "        )\n",
        "    \"\"\")\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def save_to_db(user_input, bot_response):\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"INSERT INTO chat_history (user_input, bot_response) VALUES (?, ?)\", (user_input, bot_response))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def fetch_history():\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT * FROM chat_history ORDER BY timestamp DESC LIMIT 10\")\n",
        "    rows = cursor.fetchall()\n",
        "    conn.close()\n",
        "    return rows\n",
        "\n",
        "# New: Function to delete a record by ID\n",
        "def delete_from_db(conversation_id):\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"DELETE FROM chat_history WHERE id = ?\", (conversation_id,))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "# New: Function to update a record by ID\n",
        "def update_record(conversation_id, new_user_input=None, new_bot_response=None):\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    if new_user_input:\n",
        "        cursor.execute(\"UPDATE chat_history SET user_input = ? WHERE id = ?\", (new_user_input, conversation_id))\n",
        "    if new_bot_response:\n",
        "        cursor.execute(\"UPDATE chat_history SET bot_response = ? WHERE id = ?\", (new_bot_response, conversation_id))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "# New: Function to fetch all records\n",
        "def fetch_all_history():\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT * FROM chat_history ORDER BY timestamp DESC\")\n",
        "    rows = cursor.fetchall()\n",
        "    conn.close()\n",
        "    return rows\n",
        "\n",
        "# Step 2: Set up Tavily search tool\n",
        "tavily_tool = TavilySearchResults(max_results=3)\n",
        "\n",
        "# Step 3: Define the conversation memory\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# Step 4: Define the LLM\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    max_retries=2,\n",
        "    temperature=0.7,\n",
        "    max_tokens=200,\n",
        "    api_key=gemini_api_key\n",
        ")\n",
        "\n",
        "\n",
        "# Step 5: Initialize tools\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"TavilySearch\",\n",
        "        func=tavily_tool.run,\n",
        "        description=\"Useful for answering questions requiring research or external data.\"\n",
        "    )\n",
        "]\n",
        "\n",
        "# Step 6: Create the conversational agent\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        "    memory=memory,\n",
        ")\n",
        "\n",
        "# Step 7: Implement the chatbot function\n",
        "def chatbot():\n",
        "    print(\"Welcome to the Chatbot! Type 'exit', 'quit', 'q' to end the conversation.\\n\")\n",
        "    print(\"Type 'history' to view the last 10 conversations.\\n\")\n",
        "    print(\"Type 'delete <id>' to delete a conversation by ID.\\n\")\n",
        "    print(\"Type 'update <id> <new_user_input> <new_bot_response>' to update a conversation.\\n\")\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() in [\"exit\", \"quit\", \"q\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "        elif user_input.lower() in [\"data\", \"history\", \"h\"]:\n",
        "            history = fetch_history()\n",
        "            if not history:\n",
        "                print(\"No history found.\")\n",
        "            else:\n",
        "                for idx, (id, user, bot, timestamp) in enumerate(history, 1):\n",
        "                    print(f\"{idx}. {timestamp} - You: {user} | Bot: {bot}\")\n",
        "        elif user_input.lower().startswith(\"delete\"):\n",
        "            try:\n",
        "                conversation_id = int(user_input.split()[1])\n",
        "                delete_from_db(conversation_id)\n",
        "                print(f\"Deleted conversation with ID {conversation_id}.\")\n",
        "            except (IndexError, ValueError):\n",
        "                print(\"Invalid format. Use 'delete <id>'.\")\n",
        "        elif user_input.lower().startswith(\"update\"):\n",
        "            try:\n",
        "                parts = user_input.split(maxsplit=3)\n",
        "                conversation_id = int(parts[1])\n",
        "                new_user_input = parts[2]\n",
        "                new_bot_response = parts[3]\n",
        "                update_record(conversation_id, new_user_input, new_bot_response)\n",
        "                print(f\"Updated conversation with ID {conversation_id}.\")\n",
        "            except (IndexError, ValueError):\n",
        "                print(\"Invalid format. Use 'update <id> <new_user_input> <new_bot_response>'.\")\n",
        "        else:\n",
        "            response = agent.run(user_input)\n",
        "            print(f\"Bot: {response}\")\n",
        "            save_to_db(user_input, response)\n",
        "\n",
        "# Step 8: Initialize and run the chatbot\n",
        "if __name__ == \"__main__\":\n",
        "    init_db()\n",
        "    chatbot()\n"
      ],
      "metadata": {
        "id": "VqfNDY1WWHuq",
        "outputId": "ce1c8f11-b77c-4d65-f3ed-34a7c00838f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Chatbot! Type 'exit', 'quit', 'q' to end the conversation.\n",
            "\n",
            "Type 'history' to view the last 10 conversations.\n",
            "\n",
            "Type 'delete <id>' to delete a conversation by ID.\n",
            "\n",
            "Type 'update <id> <new_user_input> <new_bot_response>' to update a conversation.\n",
            "\n",
            "You: hi\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: The question \"hi\" is a greeting and doesn't require any specific action or research.  A simple response is sufficient.\n",
            "\n",
            "Final Answer: Hi there!\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Bot: Hi there!\n",
            "You: q\n",
            "Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain.prompts.chat import ChatPromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.tools import Tool\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "import os\n",
        "\n",
        "# Step 1: Set up API keys\n",
        "os.environ[\"GEMINI_API_KEY\"] = userdata.get('GEMINI_API_KEY')\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get(\"TAVILY_API_KEY\")\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('LANGCHAIN_API_KEY')\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"quickstart\"\n",
        "\n",
        "\n",
        "# Step 2: Set up SQLite Database\n",
        "def init_db():\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS chat_history (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            user_input TEXT NOT NULL,\n",
        "            bot_response TEXT NOT NULL,\n",
        "            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP\n",
        "        )\n",
        "    \"\"\")\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def save_to_db(user_input, bot_response):\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"INSERT INTO chat_history (user_input, bot_response) VALUES (?, ?)\", (user_input, bot_response))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def fetch_history():\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT * FROM chat_history ORDER BY timestamp DESC LIMIT 10\")\n",
        "    rows = cursor.fetchall()\n",
        "    conn.close()\n",
        "    return rows\n",
        "\n",
        "# New: Function to delete conversation by ID\n",
        "def delete_from_db(conversation_id):\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # First, check if the conversation exists\n",
        "    cursor.execute(\"SELECT * FROM chat_history WHERE id = ?\", (conversation_id,))\n",
        "    row = cursor.fetchone()\n",
        "    if row:\n",
        "        # Proceed with deletion if found\n",
        "        cursor.execute(\"DELETE FROM chat_history WHERE id = ?\", (conversation_id,))\n",
        "        conn.commit()\n",
        "        print(f\"Conversation with ID {conversation_id} has been deleted.\")\n",
        "    else:\n",
        "        print(f\"No conversation found with ID {conversation_id}.\")\n",
        "\n",
        "    conn.close()\n",
        "\n",
        "\n",
        "# Step 3: Set up Tavily search tool\n",
        "tavily_tool = TavilySearchResults(max_results=3)\n",
        "\n",
        "# Step 4: Define the conversation memory\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# Step 5: Define the LLM\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    max_retries=2,\n",
        "    temperature=0.7,\n",
        "    max_tokens=200,\n",
        "    api_key=gemini_api_key\n",
        ")\n",
        "\n",
        "# Step 6: Initialize tools\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"TavilySearch\",\n",
        "        func=tavily_tool.run,\n",
        "        description=\"Useful for answering questions requiring research or external data.\"\n",
        "    )\n",
        "]\n",
        "\n",
        "# Step 7: Create the conversational agent\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        "    memory=memory,\n",
        ")\n",
        "# Step 8: Implement the chatbot function with delete feature\n",
        "def chatbot():\n",
        "    print(\"Welcome to the Chatbot! Type 'quit', 'exit', 'q' to end the conversation.\\n\")\n",
        "    print(\"Type 'history' to view the last 10 conversations.\\n\")\n",
        "    print(\"Type 'delete <id>' to delete a conversation by ID.\\n\")\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "        elif user_input.lower() in [\"history\", \"data\", \"h\"]:\n",
        "            history = fetch_history()\n",
        "            if not history:\n",
        "                print(\"No history found.\")\n",
        "            else:\n",
        "                for idx, (id, user, bot, timestamp) in enumerate(history, 1):\n",
        "                    print(f\"{idx}. {timestamp} - You: {user} | Bot: {bot}\")\n",
        "        elif user_input.lower().startswith(\"delete\"):\n",
        "            try:\n",
        "                # Extract conversation ID to delete\n",
        "                parts = user_input.split()\n",
        "                if len(parts) > 1:\n",
        "                    conversation_id = int(parts[1])\n",
        "                    delete_from_db(conversation_id)  # Delete the conversation\n",
        "                else:\n",
        "                    print(\"Please provide a conversation ID to delete.\")\n",
        "            except ValueError:\n",
        "                print(\"Invalid conversation ID. Please provide a numeric ID.\")\n",
        "        else:\n",
        "            response = agent.run(user_input)\n",
        "            print(f\"Bot: {response}\")\n",
        "\n",
        "            # Save to SQLite database\n",
        "            save_to_db(user_input, response)\n",
        "\n",
        "# Step 9: Initialize and run the chatbot\n",
        "if __name__ == \"__main__\":\n",
        "    init_db()\n",
        "    chatbot()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYkJ0HUikLCE",
        "outputId": "238327b7-f110-4630-f332-43249b53799f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-30220f2935a9>:72: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
            "<ipython-input-11-30220f2935a9>:93: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. See LangGraph documentation for more details: https://langchain-ai.github.io/langgraph/. Refer here for its pre-built ReAct agent: https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/\n",
            "  agent = initialize_agent(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Chatbot! Type 'quit', 'exit', 'q' to end the conversation.\n",
            "\n",
            "Type 'history' to view the last 10 conversations.\n",
            "\n",
            "Type 'delete <id>' to delete a conversation by ID.\n",
            "\n",
            "You: q\n",
            "Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain.prompts.chat import ChatPromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.tools import Tool\n",
        "from langchain.agents import initialize_agent, Tool, AgentType\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "\n",
        "# Step 1: Set up SQLite Database\n",
        "def init_db():\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS chat_history (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            user_input TEXT NOT NULL,\n",
        "            bot_response TEXT NOT NULL,\n",
        "            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP\n",
        "        )\n",
        "    \"\"\")\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def save_to_db(user_input, bot_response):\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"INSERT INTO chat_history (user_input, bot_response) VALUES (?, ?)\", (user_input, bot_response))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def fetch_history():\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT * FROM chat_history ORDER BY timestamp DESC LIMIT 10\")\n",
        "    rows = cursor.fetchall()\n",
        "    conn.close()\n",
        "    return rows\n",
        "\n",
        "# Step 2: Set up Tavily search tool\n",
        "tavily_tool = TavilySearchResults(max_results=3)\n",
        "\n",
        "# Step 3: Define the conversation memory\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# Step 4: Define the LLM\n",
        "\n",
        "\n",
        "# Step 5: Initialize tools\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"TavilySearch\",\n",
        "        func=tavily_tool.run,\n",
        "        description=\"Useful for answering questions requiring research or external data.\"\n",
        "    )\n",
        "]\n",
        "\n",
        "# Step 6: Create the conversational agent\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        "    memory=memory,\n",
        ")\n",
        "\n",
        "# Step 7: Implement the chatbot function\n",
        "def chatbot():\n",
        "    print(\"Welcome to the Chatbot! Type 'exit' to end the conversation.\\n\")\n",
        "    print(\"Type 'history' to view the last 10 conversations.\\n\")\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "        elif user_input.lower() == \"history\":\n",
        "            history = fetch_history()\n",
        "            if not history:\n",
        "                print(\"No history found.\")\n",
        "            else:\n",
        "                for idx, (id, user, bot, timestamp) in enumerate(history, 1):\n",
        "                    print(f\"{idx}. {timestamp} - You: {user} | Bot: {bot}\")\n",
        "        else:\n",
        "            response = agent.run(user_input)\n",
        "            print(f\"Bot: {response}\")\n",
        "            save_to_db(user_input, response)\n",
        "\n",
        "# Step 8: Initialize and run the chatbot\n",
        "if __name__ == \"__main__\":\n",
        "    init_db()\n",
        "    chatbot()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVMNi2srmBC8",
        "outputId": "cb97193f-2222-455e-bc13-a157cf7f2f9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Chatbot! Type 'exit' to end the conversation.\n",
            "\n",
            "Type 'history' to view the last 10 conversations.\n",
            "\n",
            "You: q\n",
            "Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain.prompts.chat import ChatPromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.tools import Tool\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "# Step 1: Set up SQLite Database\n",
        "def init_db():\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS chat_history (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            user_input TEXT NOT NULL,\n",
        "            bot_response TEXT NOT NULL,\n",
        "            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP\n",
        "        )\n",
        "    \"\"\")\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def save_to_db(user_input, bot_response):\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"INSERT INTO chat_history (user_input, bot_response) VALUES (?, ?)\", (user_input, bot_response))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def fetch_history():\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT * FROM chat_history ORDER BY timestamp DESC LIMIT 10\")\n",
        "    rows = cursor.fetchall()\n",
        "    conn.close()\n",
        "    return rows\n",
        "\n",
        "# New: Function to delete a record by ID\n",
        "def delete_from_db(conversation_id):\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"DELETE FROM chat_history WHERE id = ?\", (conversation_id,))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "# New: Function to update a record by ID\n",
        "def update_record(conversation_id, new_user_input=None, new_bot_response=None):\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    if new_user_input:\n",
        "        cursor.execute(\"UPDATE chat_history SET user_input = ? WHERE id = ?\", (new_user_input, conversation_id))\n",
        "    if new_bot_response:\n",
        "        cursor.execute(\"UPDATE chat_history SET bot_response = ? WHERE id = ?\", (new_bot_response, conversation_id))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "# New: Function to fetch all records\n",
        "def fetch_all_history():\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT * FROM chat_history ORDER BY timestamp DESC\")\n",
        "    rows = cursor.fetchall()\n",
        "    conn.close()\n",
        "    return rows\n",
        "\n",
        "# Step 2: Set up Tavily search tool\n",
        "tavily_tool = TavilySearchResults(max_results=3)\n",
        "\n",
        "# Step 3: Define the conversation memory\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# Step 4: Define the LLM\n",
        "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=200)\n",
        "\n",
        "# Step 5: Initialize tools\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"TavilySearch\",\n",
        "        func=tavily_tool.run,\n",
        "        description=\"Useful for answering questions requiring research or external data.\"\n",
        "    )\n",
        "]\n",
        "\n",
        "# Step 6: Create the conversational agent\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        "    memory=memory,\n",
        ")\n",
        "\n",
        "# Step 7: Implement the chatbot function\n",
        "def chatbot():\n",
        "    print(\"Welcome to the Chatbot! Type 'exit' to end the conversation.\\n\")\n",
        "    print(\"Type 'history' to view the last 10 conversations.\\n\")\n",
        "    print(\"Type 'delete <id>' to delete a conversation by ID.\\n\")\n",
        "    print(\"Type 'update <id> <new_user_input> <new_bot_response>' to update a conversation.\\n\")\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == \"exit\":\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "        elif user_input.lower() == \"history\":\n",
        "            history = fetch_history()\n",
        "            if not history:\n",
        "                print(\"No history found.\")\n",
        "            else:\n",
        "                for idx, (id, user, bot, timestamp) in enumerate(history, 1):\n",
        "                    print(f\"{idx}. {timestamp} - You: {user} | Bot: {bot}\")\n",
        "        elif user_input.lower().startswith(\"delete\"):\n",
        "            try:\n",
        "                conversation_id = int(user_input.split()[1])\n",
        "                delete_from_db(conversation_id)\n",
        "                print(f\"Deleted conversation with ID {conversation_id}.\")\n",
        "            except (IndexError, ValueError):\n",
        "                print(\"Invalid format. Use 'delete <id>'.\")\n",
        "        elif user_input.lower().startswith(\"update\"):\n",
        "            try:\n",
        "                parts = user_input.split(maxsplit=3)\n",
        "                conversation_id = int(parts[1])\n",
        "                new_user_input = parts[2]\n",
        "                new_bot_response = parts[3]\n",
        "                update_record(conversation_id, new_user_input, new_bot_response)\n",
        "                print(f\"Updated conversation with ID {conversation_id}.\")\n",
        "            except (IndexError, ValueError):\n",
        "                print(\"Invalid format. Use 'update <id> <new_user_input> <new_bot_response>'.\")\n",
        "        else:\n",
        "            response = agent.run(user_input)\n",
        "            print(f\"Bot: {response}\")\n",
        "            save_to_db(user_input, response)\n",
        "\n",
        "# Step 8: Initialize and run the chatbot\n",
        "if __name__ == \"__main__\":\n",
        "    init_db()\n",
        "    chatbot()\n"
      ],
      "metadata": {
        "id": "71gpPtiYMn1E",
        "outputId": "afef818c-42bd-4b86-acc6-aefcfa6d2a30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValidationError",
          "evalue": "1 validation error for OpenAI\n  Value error, Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. [type=value_error, input_value={'temperature': 0.7, 'max...ne, 'http_client': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/value_error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-74e86e149825>\u001b[0m in \u001b[0;36m<cell line: 75>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;31m# Step 4: Define the LLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m \u001b[0mllm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;31m# Step 5: Initialize tools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarn_if_direct_instance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                         \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                         \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 obj.__init__ = functools.wraps(obj.__init__)(  # type: ignore[misc]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/load/serializable.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;34m\"\"\"\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/main.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;31m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mvalidated_self\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pydantic_validator__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalidated_self\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             warnings.warn(\n",
            "\u001b[0;31mValidationError\u001b[0m: 1 validation error for OpenAI\n  Value error, Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. [type=value_error, input_value={'temperature': 0.7, 'max...ne, 'http_client': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/value_error"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain.prompts.chat import ChatPromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.tools import Tool\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "# Step 1: Set up SQLite Database\n",
        "def init_db():\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS chat_history (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            user_input TEXT NOT NULL,\n",
        "            bot_response TEXT NOT NULL,\n",
        "            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP\n",
        "        )\n",
        "    \"\"\")\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def save_to_db(user_input, bot_response):\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"INSERT INTO chat_history (user_input, bot_response) VALUES (?, ?)\", (user_input, bot_response))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def fetch_history():\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT * FROM chat_history ORDER BY timestamp DESC LIMIT 10\")\n",
        "    rows = cursor.fetchall()\n",
        "    conn.close()\n",
        "    return rows\n",
        "\n",
        "# Step 2: Set up Tavily search tool\n",
        "tavily_tool = TavilySearchResults(max_results=3)\n",
        "\n",
        "# Step 3: Define the conversation memory\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# Step 4: Define the LLM\n",
        "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=200)\n",
        "\n",
        "# Step 5: Initialize tools\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"TavilySearch\",\n",
        "        func=tavily_tool.run,\n",
        "        description=\"Useful for answering questions requiring research or external data.\"\n",
        "    )\n",
        "]\n",
        "\n",
        "# Step 6: Create the conversational agent\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        "    memory=memory,\n",
        ")\n",
        "\n",
        "# Step 7: Define medical keywords and filtering function\n",
        "MEDICAL_KEYWORDS = [\n",
        "    \"medicine\", \"symptoms\", \"diagnosis\", \"treatment\", \"disease\", \"doctor\",\n",
        "    \"hospital\", \"health\", \"surgery\", \"therapy\", \"infection\", \"pharmacy\", \"drug\"\n",
        "]\n",
        "\n",
        "def is_medical_prompt(prompt):\n",
        "    \"\"\"Check if the prompt contains medical-related keywords.\"\"\"\n",
        "    return any(keyword.lower() in prompt.lower() for keyword in MEDICAL_KEYWORDS)\n",
        "\n",
        "# Step 8: Implement the chatbot function\n",
        "def chatbot():\n",
        "    print(\"Welcome to the Medical Chatbot! I only answer medical-related questions.\\n\")\n",
        "    print(\"Type 'exit' to end the conversation.\\n\")\n",
        "    print(\"Type 'history' to view the last 10 conversations.\\n\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() in [\"exit\", \"quit\", \"q\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "        elif user_input.lower() == \"history\":\n",
        "            history = fetch_history()\n",
        "            if not history:\n",
        "                print(\"No history found.\")\n",
        "            else:\n",
        "                for idx, (id, user, bot, timestamp) in enumerate(history, 1):\n",
        "                    print(f\"{idx}. {timestamp} - You: {user} | Bot: {bot}\")\n",
        "        else:\n",
        "            if is_medical_prompt(user_input):\n",
        "                response = agent.run(user_input)\n",
        "                print(f\"Bot: {response}\")\n",
        "                save_to_db(user_input, response)\n",
        "            else:\n",
        "                print(\"I'm sorry, I can only assist with medical-related questions.\")\n",
        "\n",
        "# Step 9: Initialize and run the chatbot\n",
        "if __name__ == \"__main__\":\n",
        "    init_db()\n",
        "    chatbot()\n"
      ],
      "metadata": {
        "id": "d76mv22Vtxr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain.prompts.chat import ChatPromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.tools import Tool\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from graphviz import Digraph\n",
        "\n",
        "# Step 1: Set up SQLite Database\n",
        "def init_db():\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS chat_history (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            user_input TEXT NOT NULL,\n",
        "            bot_response TEXT NOT NULL,\n",
        "            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP\n",
        "        )\n",
        "    \"\"\")\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def save_to_db(user_input, bot_response):\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"INSERT INTO chat_history (user_input, bot_response) VALUES (?, ?)\", (user_input, bot_response))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "# Step 2: Set up Tavily search tool\n",
        "tavily_tool = TavilySearchResults(max_results=3)\n",
        "\n",
        "# Step 3: Define the conversation memory\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# Step 4: Define the LLM\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    max_retries=2,\n",
        "    temperature=0.7,\n",
        "    max_tokens=200,\n",
        "    api_key=gemini_api_key\n",
        ")\n",
        "\n",
        "# Step 5: Initialize tools\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"TavilySearch\",\n",
        "        func=tavily_tool.run,\n",
        "        description=\"Useful for answering questions requiring research or external data.\"\n",
        "    )\n",
        "]\n",
        "\n",
        "# Step 6: Create the conversational agent\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        "    memory=memory,\n",
        ")\n",
        "\n",
        "# Step 7: Define medical keywords and filtering function\n",
        "MEDICAL_KEYWORDS = [\n",
        "    \"medicine\", \"symptoms\", \"diagnosis\", \"treatment\", \"disease\", \"doctor\",\n",
        "    \"hospital\", \"health\", \"surgery\", \"therapy\", \"infection\", \"pharmacy\", \"drug\"\n",
        "]\n",
        "\n",
        "def is_medical_prompt(prompt):\n",
        "    \"\"\"Check if the prompt contains medical-related keywords.\"\"\"\n",
        "    return any(keyword.lower() in prompt.lower() for keyword in MEDICAL_KEYWORDS)\n",
        "\n",
        "# Step 8: Initialize workflow visualization\n",
        "workflow_graph = Digraph(\"Chatbot Workflow\", format=\"png\")\n",
        "workflow_graph.attr(rankdir=\"LR\")  # Set direction of flow\n",
        "workflow_graph.node(\"Start\", shape=\"ellipse\", style=\"filled\", color=\"lightblue\")\n",
        "workflow_graph.node(\"Filter Prompt\", shape=\"box\", style=\"filled\", color=\"lightgreen\")\n",
        "workflow_graph.node(\"Generate Response\", shape=\"box\", style=\"filled\", color=\"lightyellow\")\n",
        "workflow_graph.node(\"Save to DB\", shape=\"box\", style=\"filled\", color=\"orange\")\n",
        "workflow_graph.node(\"End\", shape=\"ellipse\", style=\"filled\", color=\"lightblue\")\n",
        "workflow_graph.edges([(\"Start\", \"Filter Prompt\"), (\"Filter Prompt\", \"Generate Response\"),\n",
        "                      (\"Generate Response\", \"Save to DB\"), (\"Save to DB\", \"End\")])\n",
        "\n",
        "def render_workflow():\n",
        "    \"\"\"Render and display the workflow graph.\"\"\"\n",
        "    workflow_graph.render(\"chatbot_workflow\", view=True)\n",
        "\n",
        "# Step 9: Implement the chatbot function\n",
        "def chatbot():\n",
        "    print(\"Welcome to the Medical Chatbot! I only answer medical-related questions.\\n\")\n",
        "    print(\"Type 'exit' to end the conversation.\\n\")\n",
        "    print(\"Type 'history' to view the last 10 conversations.\\n\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() in [\"exit\", \"quit\", \"q\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            render_workflow()  # Display workflow graph at the end\n",
        "            break\n",
        "        elif user_input.lower() == \"history\":\n",
        "            history = fetch_history()\n",
        "            if not history:\n",
        "                print(\"No history found.\")\n",
        "            else:\n",
        "                for idx, (id, user, bot, timestamp) in enumerate(history, 1):\n",
        "                    print(f\"{idx}. {timestamp} - You: {user} | Bot: {bot}\")\n",
        "        else:\n",
        "            workflow_graph.node(user_input, shape=\"ellipse\", style=\"dashed\", color=\"grey\")\n",
        "            workflow_graph.edge(\"Start\", user_input)\n",
        "\n",
        "            if is_medical_prompt(user_input):\n",
        "                workflow_graph.edge(user_input, \"Filter Prompt\")\n",
        "                response = agent.run(user_input)\n",
        "                workflow_graph.edge(\"Filter Prompt\", \"Generate Response\")\n",
        "                print(f\"Bot: {response}\")\n",
        "                save_to_db(user_input, response)\n",
        "                workflow_graph.edge(\"Generate Response\", \"Save to DB\")\n",
        "            else:\n",
        "                print(\"I'm sorry, I can only assist with medical-related questions.\")\n",
        "                workflow_graph.edge(user_input, \"Filter Prompt\")\n",
        "                workflow_graph.edge(\"Filter Prompt\", \"End\")\n",
        "\n",
        "# Step 10: Initialize and run the chatbot\n",
        "if __name__ == \"__main__\":\n",
        "    init_db()\n",
        "    chatbot()\n"
      ],
      "metadata": {
        "id": "bm4RgaLBvrBt",
        "outputId": "7761b064-876d-40be-ddc1-a4ecb83ef72d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Medical Chatbot! I only answer medical-related questions.\n",
            "\n",
            "Type 'exit' to end the conversation.\n",
            "\n",
            "Type 'history' to view the last 10 conversations.\n",
            "\n",
            "You: hi\n",
            "I'm sorry, I can only assist with medical-related questions.\n",
            "You: doctor\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: The question \"doctor\" is too broad.  I need to clarify what information is being requested.  Do they want a definition, a list of types of doctors, or something else?  I'll try to get more context using a search.\n",
            "\n",
            "Action: TavilySearch\n",
            "\n",
            "Action Input: \"What is a doctor?\"\n",
            "\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m[{'url': 'https://www.careerexplorer.com/careers/doctor/', 'content': 'A doctor is a medical professional who has completed the necessary education and training to diagnose, treat, and prevent illnesses and injuries in individuals. Doctors provide essential medical care, prescribe medication, perform surgeries, and offer preventative measures to help people maintain their health. They also conduct research, educate patients and the public, and work'}, {'url': 'https://www.indeed.com/career-advice/finding-a-job/what-is-doctor', 'content': 'A doctor is someone who is experienced and certified to practice medicine to help maintain or restore physical and mental health. A doctor interacts with patients, diagnosing medical problems and successfully treating illness or injury. There are many specific areas in the field of medicine that students can study.'}, {'url': 'https://www.merriam-webster.com/dictionary/doctor', 'content': 'The meaning of DOCTOR is an eminent theologian declared a sound expounder of doctrine by the Roman Catholic Church called also doctor of the church. How to use doctor in a sentence.'}]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThought:The TavilySearch results provide a good definition of a doctor.  I can synthesize this information to give a concise answer.\n",
            "\n",
            "Thought:I now know the final answer.\n",
            "\n",
            "Final Answer: A doctor is a medical professional who has completed extensive education and training to diagnose, treat, and prevent illnesses and injuries.  They provide medical care, prescribe medication, perform surgeries, and offer preventative measures to maintain health.  There are many specialties within the medical field.\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Bot: A doctor is a medical professional who has completed extensive education and training to diagnose, treat, and prevent illnesses and injuries.  They provide medical care, prescribe medication, perform surgeries, and offer preventative measures to maintain health.  There are many specialties within the medical field.\n",
            "You: a\n",
            "I'm sorry, I can only assist with medical-related questions.\n",
            "You: q\n",
            "Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain.prompts.chat import ChatPromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.tools import Tool\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from graphviz import Digraph\n",
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# Step 1: Set up SQLite Database\n",
        "def init_db():\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS chat_history (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            user_input TEXT NOT NULL,\n",
        "            bot_response TEXT NOT NULL,\n",
        "            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP\n",
        "        )\n",
        "    \"\"\")\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def save_to_db(user_input, bot_response):\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"INSERT INTO chat_history (user_input, bot_response) VALUES (?, ?)\", (user_input, bot_response))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def fetch_history():\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT * FROM chat_history ORDER BY timestamp DESC LIMIT 10\")\n",
        "    rows = cursor.fetchall()\n",
        "    conn.close()\n",
        "    return rows\n",
        "\n",
        "# Step 2: Set up Tavily search tool\n",
        "tavily_tool = TavilySearchResults(max_results=3)\n",
        "\n",
        "# Step 3: Define the conversation memory\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# Step 4: Define the LLM\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    max_retries=2,\n",
        "    temperature=0.7,\n",
        "    max_tokens=200,\n",
        "    api_key=gemini_api_key\n",
        ")\n",
        "\n",
        "# Step 5: Initialize tools\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"TavilySearch\",\n",
        "        func=tavily_tool.run,\n",
        "        description=\"Useful for answering questions requiring research or external data.\"\n",
        "    )\n",
        "]\n",
        "\n",
        "# Step 6: Create the conversational agent\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        "    memory=memory,\n",
        ")\n",
        "\n",
        "# Step 7: Define medical keywords and filtering function\n",
        "MEDICAL_KEYWORDS = [\n",
        "    \"medicine\", \"symptoms\", \"diagnosis\", \"treatment\", \"disease\", \"doctor\",\n",
        "    \"hospital\", \"health\", \"surgery\", \"therapy\", \"infection\", \"pharmacy\", \"drug\"\n",
        "]\n",
        "\n",
        "def is_medical_prompt(prompt):\n",
        "    \"\"\"Check if the prompt contains medical-related keywords.\"\"\"\n",
        "    return any(keyword.lower() in prompt.lower() for keyword in MEDICAL_KEYWORDS)\n",
        "\n",
        "# Step 8: Initialize workflow visualization with Graphviz\n",
        "workflow_graph = Digraph(\"Chatbot Workflow\", format=\"png\")\n",
        "workflow_graph.attr(rankdir=\"LR\")\n",
        "workflow_graph.node(\"Start\", shape=\"ellipse\", style=\"filled\", color=\"lightblue\")\n",
        "workflow_graph.node(\"Filter Prompt\", shape=\"box\", style=\"filled\", color=\"lightgreen\")\n",
        "workflow_graph.node(\"Generate Response\", shape=\"box\", style=\"filled\", color=\"lightyellow\")\n",
        "workflow_graph.node(\"Save to DB\", shape=\"box\", style=\"filled\", color=\"orange\")\n",
        "workflow_graph.node(\"End\", shape=\"ellipse\", style=\"filled\", color=\"lightblue\")\n",
        "workflow_graph.edges([(\"Start\", \"Filter Prompt\"), (\"Filter Prompt\", \"Generate Response\"),\n",
        "                      (\"Generate Response\", \"Save to DB\"), (\"Save to DB\", \"End\")])\n",
        "\n",
        "def render_workflow():\n",
        "    \"\"\"Render and display the workflow graph.\"\"\"\n",
        "    workflow_graph.render(\"chatbot_workflow\", view=True)\n",
        "\n",
        "# Step 9: Chatbot logic with state graph integration\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "def chatbot_logic(state: State):\n",
        "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
        "\n",
        "graph_builder.add_node(\"chatbot_logic\", chatbot_logic)\n",
        "graph_builder.add_edge(START, \"chatbot_logic\")\n",
        "graph_builder.add_edge(\"chatbot_logic\", END)\n",
        "graph = graph_builder.compile()\n",
        "\n",
        "# Step 10: Chatbot Execution Function\n",
        "def chatbot():\n",
        "    print(\"Welcome to the Medical Chatbot! I only answer medical-related questions.\\n\")\n",
        "    print(\"Type 'exit' to end the conversation.\\n\")\n",
        "    print(\"Type 'history' to view the last 10 conversations.\\n\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() in [\"exit\", \"quit\", \"q\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            render_workflow()\n",
        "            try:\n",
        "                display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "            except Exception:\n",
        "                print(\"Graph rendering failed.\")\n",
        "            break\n",
        "        elif user_input.lower() == \"history\":\n",
        "            history = fetch_history()\n",
        "            if not history:\n",
        "                print(\"No history found.\")\n",
        "            else:\n",
        "                for idx, (id, user, bot, timestamp) in enumerate(history, 1):\n",
        "                    print(f\"{idx}. {timestamp} - You: {user} | Bot: {bot}\")\n",
        "        else:\n",
        "            workflow_graph.node(user_input, shape=\"ellipse\", style=\"dashed\", color=\"grey\")\n",
        "            workflow_graph.edge(\"Start\", user_input)\n",
        "\n",
        "            if is_medical_prompt(user_input):\n",
        "                workflow_graph.edge(user_input, \"Filter Prompt\")\n",
        "                response = agent.run(user_input)\n",
        "                workflow_graph.edge(\"Filter Prompt\", \"Generate Response\")\n",
        "                print(f\"Bot: {response}\")\n",
        "                save_to_db(user_input, response)\n",
        "                workflow_graph.edge(\"Generate Response\", \"Save to DB\")\n",
        "            else:\n",
        "                print(\"I'm sorry, I can only assist with medical-related questions.\")\n",
        "                workflow_graph.edge(user_input, \"Filter Prompt\")\n",
        "                workflow_graph.edge(\"Filter Prompt\", \"End\")\n",
        "\n",
        "# Step 11: Initialize and run the chatbot\n",
        "if __name__ == \"__main__\":\n",
        "    init_db()\n",
        "    chatbot()\n"
      ],
      "metadata": {
        "id": "bkxZ_43wynOl",
        "outputId": "8b4b94ea-484a-4932-89f8-d4282d46a48a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Medical Chatbot! I only answer medical-related questions.\n",
            "\n",
            "Type 'exit' to end the conversation.\n",
            "\n",
            "Type 'history' to view the last 10 conversations.\n",
            "\n",
            "You: What are the symptoms of diabetes?\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to use TavilySearch to find information on the symptoms of diabetes.\n",
            "\n",
            "Action: TavilySearch\n",
            "\n",
            "Action Input: \"symptoms of diabetes\"\n",
            "\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m[{'url': 'https://www.webmd.com/diabetes/understanding-diabetes-symptoms', 'content': 'Are you at risk?\\nRecommended for You\\nTop doctors in ,\\nFind more top doctors on\\nHealth Solutions from Our Sponsors\\nMore from WebMD\\nRelated Links\\nPolicies\\nAbout\\nOur Apps\\nFor Advertisers\\n 2005 - 2023 WebMD LLC, an Internet Brands company. \"\\nNational Institute of Diabetes and Digestive and Kidney Diseases: Symptoms & Causes of Gestational Diabetes.\\nGeisinger Health: 3 reasons diabetic wounds are slow to heal.\\nAmerican Diabetes Association: Hyperosmolar Hyperglycemic Nonketotic Syndrome (HHNS), Hypoglycemia (Low Blood Glucose), Skin Complications.\\n You might feel:\\nYou might notice:\\nHyperglycemia\\nHyperglycemia, or high blood sugar, causes many of the warning signs of diabetes listed above, including:\\nDiabetic Coma\\nIts official name is hyperosmolar hyperglycemic nonketotic syndrome (HHNS). Conditions\\nDrugs & Supplements\\nWell-Being\\nMore\\nEarly Signs and Symptoms of Diabetes\\nHow can you tell if you have diabetes? Warning Signs of Diabetes Complications\\nSigns of type 2 diabetes\\' complications may include:\\nLearn about what you can do to lower your risk of diabetes complications.\\n'}, {'url': 'https://www.cdc.gov/diabetes/signs-symptoms/index.html', 'content': \"Symptoms of type 2 diabetes. Type 2 diabetes symptoms often take several years to develop. Some people don't notice any symptoms at all. Type 2 diabetes usually starts when you're an adult, though more and more children and teens are developing it. Because symptoms are hard to spot, it's important to know the risk factors for type 2 diabetes.\"}, {'url': 'https://diabetes.org/about-diabetes/warning-signs-symptoms', 'content': \"Learn your risk for type 2 and take steps to prevent it\\nLearn the ins and outs of diabetes and steps for better care\\nLearn what you can do to keep your child with diabetes safe at school\\nWhat you need to know about gestational diabetes\\nMake a plan to be prepared when illness strikes\\nSign up to receive timely information on topics to help you and your family live a healthy life\\nBringing ADA's evidence-based guidelines and perspective directly to you in the store so you can make informed choices.\\n Diabetes Prevention Program\\nIf you are at risk for developing diabetes or have prediabetes, find a Diabetes Prevention Program near you to cut your risk in half!\\nPrediabetes\\nHaving prediabetes means your blood glucose (blood sugar) levels are high, but not high enough to be diagnosed with diabetes. Breadcrumb\\nWarning Signs and Symptoms\\nKnow the warning signs and symptoms of diabetes and diabetes complications so you can take action to improve your health\\nThe following symptoms of diabetes are typical. 2451 Crystal Drive, Suite 900\\nArlington, VA 22202\\nP.O. Box 7023\\nMerrifield, VA 22116-7023\\nCenter for Information\\nMondayFriday\\n9 am5:30 pm ET\\nCopyright 19952024. Type 2 Diabetes Risk Test\\nFind out if you are at risk for developing type 2 diabetes with our 60-second Type 2 Diabetes Risk Test.\\n\"}]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThought:The TavilySearch results provide links to websites with information on diabetes symptoms.  I need to examine the content to synthesize a concise answer.\n",
            "\n",
            "Action: Analyze Observation\n",
            "\n",
            "Action Input:The content from the TavilySearch results.\n",
            "\u001b[0m\n",
            "Observation: Analyze Observation is not a valid tool, try one of [TavilySearch].\n",
            "Thought:\u001b[32;1m\u001b[1;3mThought: I will need to manually extract the relevant information from the observation.  The observation contains URLs to websites discussing diabetes symptoms.  I will attempt to summarize the common symptoms mentioned across these sources.\n",
            "\n",
            "\n",
            "Action: Analyze Observation\n",
            "\n",
            "Action Input:The text content from the TavilySearch results.  Specifically focusing on mentions of symptoms.\n",
            "\u001b[0m\n",
            "Observation: Analyze Observation is not a valid tool, try one of [TavilySearch].\n",
            "Thought:\u001b[32;1m\u001b[1;3mThought: I will manually synthesize the information from the provided text snippets.  The snippets mention increased thirst, frequent urination, unexplained weight loss, increased hunger, fatigue, blurred vision, slow-healing sores, frequent infections, and numbness or tingling in the hands or feet.\n",
            "\n",
            "Thought: I now know the final answer.\n",
            "\n",
            "Final Answer: Common symptoms of diabetes include increased thirst and frequent urination, unexplained weight loss, increased hunger, fatigue, blurred vision, slow-healing sores, frequent infections, and numbness or tingling in the hands or feet.  It's important to note that some individuals may not experience any noticeable symptoms, particularly in the early stages of type 2 diabetes.\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Bot: Common symptoms of diabetes include increased thirst and frequent urination, unexplained weight loss, increased hunger, fatigue, blurred vision, slow-healing sores, frequent infections, and numbness or tingling in the hands or feet.  It's important to note that some individuals may not experience any noticeable symptoms, particularly in the early stages of type 2 diabetes.\n",
            "You: exit\n",
            "Goodbye!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "python.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "google": {
      "image_path": "/static/site-assets/images/docs/logo-python.svg",
      "keywords": [
        "examples",
        "gemini",
        "beginner",
        "googleai",
        "quickstart",
        "python",
        "text",
        "chat",
        "vision",
        "embed"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}