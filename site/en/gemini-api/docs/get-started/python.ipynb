{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -U langgraph langsmith langchain_google_genai\n"
      ],
      "metadata": {
        "id": "yJXRL2rXkcrz"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('LANGCHAIN_API_KEY')\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"quickstart\"\n",
        "\n",
        "gemini_api_key = userdata.get('GEMINI_API_KEY')"
      ],
      "metadata": {
        "id": "5hUaBbXCkgph"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    max_retries=2,\n",
        "    api_key=gemini_api_key\n",
        ")\n",
        "\n",
        "llm.invoke(\"greet me\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7h7XwdK9kinA",
        "outputId": "ebe5f487-cee4-45ab-9e19-0058534dca6d"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Hello there!\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-915e5109-fd79-436a-877b-bff1ab812475-0', usage_metadata={'input_tokens': 3, 'output_tokens': 4, 'total_tokens': 7, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -U tavily-python langchain_community\n"
      ],
      "metadata": {
        "id": "_l5YrxE3kmto"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get(\"TAVILY_API_KEY\")"
      ],
      "metadata": {
        "id": "ACr2msJIlZje"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -U langsmith LangSmithLogger\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ccuxw_G1n5jg",
        "outputId": "5b54ce5f-6533-4a76-9758-020d2d2805c8"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langsmith in /usr/local/lib/python3.10/dist-packages (0.2.4)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement LangSmithLogger (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for LangSmithLogger\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -U langchain langsmith langchain_community\n"
      ],
      "metadata": {
        "id": "qaiPWCMIn1S3"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    max_retries=2,\n",
        "    temperature=0.7,\n",
        "    max_tokens=200,\n",
        "    api_key=gemini_api_key\n",
        ")\n",
        "\n",
        "llm.invoke(\"greet me\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzeRUaHZuiUm",
        "outputId": "ba0ee45d-62b6-4437-f6dd-cba8faee71df"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Hello there!\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-95dd8f03-2119-48af-9753-bdf54193653c-0', usage_metadata={'input_tokens': 3, 'output_tokens': 4, 'total_tokens': 7, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain.prompts.chat import ChatPromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.tools import Tool\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "import os\n",
        "\n",
        "# Step 1: Set up API keys\n",
        "os.environ[\"GEMINI_API_KEY\"] = userdata.get('GEMINI_API_KEY')\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get(\"TAVILY_API_KEY\")\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('LANGCHAIN_API_KEY')\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"quickstart\"\n",
        "\n",
        "\n",
        "# Step 2: Set up SQLite Database\n",
        "def init_db():\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS chat_history (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            user_input TEXT NOT NULL,\n",
        "            bot_response TEXT NOT NULL,\n",
        "            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP\n",
        "        )\n",
        "    \"\"\")\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def save_to_db(user_input, bot_response):\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"INSERT INTO chat_history (user_input, bot_response) VALUES (?, ?)\", (user_input, bot_response))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def fetch_history():\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT * FROM chat_history ORDER BY timestamp DESC LIMIT 10\")\n",
        "    rows = cursor.fetchall()\n",
        "    conn.close()\n",
        "    return rows\n",
        "\n",
        "# New: Function to delete conversation by ID\n",
        "def delete_from_db(conversation_id):\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # First, check if the conversation exists\n",
        "    cursor.execute(\"SELECT * FROM chat_history WHERE id = ?\", (conversation_id,))\n",
        "    row = cursor.fetchone()\n",
        "    if row:\n",
        "        # Proceed with deletion if found\n",
        "        cursor.execute(\"DELETE FROM chat_history WHERE id = ?\", (conversation_id,))\n",
        "        conn.commit()\n",
        "        print(f\"Conversation with ID {conversation_id} has been deleted.\")\n",
        "    else:\n",
        "        print(f\"No conversation found with ID {conversation_id}.\")\n",
        "\n",
        "    conn.close()\n",
        "\n",
        "\n",
        "# Step 3: Set up Tavily search tool\n",
        "tavily_tool = TavilySearchResults(max_results=3)\n",
        "\n",
        "# Step 4: Define the conversation memory\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# Step 5: Define the LLM\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    max_retries=2,\n",
        "    temperature=0.7,\n",
        "    max_tokens=200,\n",
        "    api_key=gemini_api_key\n",
        ")\n",
        "\n",
        "# Step 6: Initialize tools\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"TavilySearch\",\n",
        "        func=tavily_tool.run,\n",
        "        description=\"Useful for answering questions requiring research or external data.\"\n",
        "    )\n",
        "]\n",
        "\n",
        "# Step 7: Create the conversational agent\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        "    memory=memory,\n",
        ")\n",
        "# Step 8: Implement the chatbot function with delete feature\n",
        "def chatbot():\n",
        "    print(\"Welcome to the Chatbot! Type 'exit' to end the conversation.\\n\")\n",
        "    print(\"Type 'history' to view the last 10 conversations.\\n\")\n",
        "    print(\"Type 'delete <id>' to delete a conversation by ID.\\n\")\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "        elif user_input.lower() in [\"history\", \"data\", \"h\"]:\n",
        "            history = fetch_history()\n",
        "            if not history:\n",
        "                print(\"No history found.\")\n",
        "            else:\n",
        "                for idx, (id, user, bot, timestamp) in enumerate(history, 1):\n",
        "                    print(f\"{idx}. {timestamp} - You: {user} | Bot: {bot}\")\n",
        "        elif user_input.lower().startswith(\"delete\"):\n",
        "            try:\n",
        "                # Extract conversation ID to delete\n",
        "                parts = user_input.split()\n",
        "                if len(parts) > 1:\n",
        "                    conversation_id = int(parts[1])\n",
        "                    delete_from_db(conversation_id)  # Delete the conversation\n",
        "                else:\n",
        "                    print(\"Please provide a conversation ID to delete.\")\n",
        "            except ValueError:\n",
        "                print(\"Invalid conversation ID. Please provide a numeric ID.\")\n",
        "        else:\n",
        "            response = agent.run(user_input)\n",
        "            print(f\"Bot: {response}\")\n",
        "\n",
        "            # Save to SQLite database\n",
        "            save_to_db(user_input, response)\n",
        "\n",
        "# Step 9: Initialize and run the chatbot\n",
        "if __name__ == \"__main__\":\n",
        "    init_db()\n",
        "    chatbot()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYkJ0HUikLCE",
        "outputId": "a6fb1f27-f2d6-4da0-e540-bf2e3615bed8"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Chatbot! Type 'exit' to end the conversation.\n",
            "\n",
            "Type 'history' to view the last 10 conversations.\n",
            "\n",
            "Type 'delete <id>' to delete a conversation by ID.\n",
            "\n",
            "You: h\n",
            "1. 2024-12-22 00:31:23 - You: 671255be-8db3-4d4b-9667-f1c8e020cac0 | Bot: I cannot find any information associated with the UUID \"671255be-8db3-4d4b-9667-f1c8e020cac0\" using the available tools.  More context is needed.\n",
            "2. 2024-12-22 00:21:45 - You: Remember my name? | Bot: I don't remember your name. Please tell me what it is.\n",
            "3. 2024-12-22 00:21:24 - You: Hi there! My name is Junaid. | Bot: Hi Junaid!  It's nice to meet you.\n",
            "4. 2024-12-22 00:20:21 - You: What's a 'node' in LangGraph? | Bot: In LangGraph, a node represents a function or computation step.  Each node performs a specific task, such as processing input or executing a tool.  Nodes can represent LLM agents, with edges defining communication channels between them.  They interact by reading and writing to a shared state.\n",
            "5. 2024-12-22 00:19:37 - You: hi | Bot: Hi there!\n",
            "6. 2024-12-22 00:10:15 - You: my name is Abdul Basit | Bot: There is no question to answer.  The statement simply provides a name.\n",
            "7. 2024-12-22 00:09:52 - You: basit | Bot: Basit means simple or easy in Turkish.\n",
            "8. 2024-12-22 00:09:42 - You: remember my name? | Bot: I don't remember your name from previous conversations. Please tell me your name.\n",
            "9. 2024-12-22 00:09:18 - You: i am Abdul Basit | Bot: Acknowledged.  My name is Abdul Basit.\n",
            "10. 2024-12-22 00:08:50 - You: how is the weather in karachi | Bot: The current temperature in Karachi is 17.6 degrees Celsius.\n",
            "You: delete 3\n",
            "No conversation found with ID 3.\n",
            "You: h\n",
            "1. 2024-12-22 00:31:23 - You: 671255be-8db3-4d4b-9667-f1c8e020cac0 | Bot: I cannot find any information associated with the UUID \"671255be-8db3-4d4b-9667-f1c8e020cac0\" using the available tools.  More context is needed.\n",
            "2. 2024-12-22 00:21:45 - You: Remember my name? | Bot: I don't remember your name. Please tell me what it is.\n",
            "3. 2024-12-22 00:21:24 - You: Hi there! My name is Junaid. | Bot: Hi Junaid!  It's nice to meet you.\n",
            "4. 2024-12-22 00:20:21 - You: What's a 'node' in LangGraph? | Bot: In LangGraph, a node represents a function or computation step.  Each node performs a specific task, such as processing input or executing a tool.  Nodes can represent LLM agents, with edges defining communication channels between them.  They interact by reading and writing to a shared state.\n",
            "5. 2024-12-22 00:19:37 - You: hi | Bot: Hi there!\n",
            "6. 2024-12-22 00:10:15 - You: my name is Abdul Basit | Bot: There is no question to answer.  The statement simply provides a name.\n",
            "7. 2024-12-22 00:09:52 - You: basit | Bot: Basit means simple or easy in Turkish.\n",
            "8. 2024-12-22 00:09:42 - You: remember my name? | Bot: I don't remember your name from previous conversations. Please tell me your name.\n",
            "9. 2024-12-22 00:09:18 - You: i am Abdul Basit | Bot: Acknowledged.  My name is Abdul Basit.\n",
            "10. 2024-12-22 00:08:50 - You: how is the weather in karachi | Bot: The current temperature in Karachi is 17.6 degrees Celsius.\n",
            "You: delete cbd323fa-bbef-408c-972b-44dc70e575dc\n",
            "Invalid conversation ID. Please provide a numeric ID.\n",
            "You: q\n",
            "Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain.prompts.chat import ChatPromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.tools import Tool\n",
        "from langchain.agents import initialize_agent, Tool, AgentType\n",
        "from langchain.memory import ConversationBufferMemory\n"
      ],
      "metadata": {
        "id": "z7PqaNUdnkqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Set up SQLite Database\n",
        "def init_db():\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS chat_history (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            user_input TEXT NOT NULL,\n",
        "            bot_response TEXT NOT NULL,\n",
        "            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP\n",
        "        )\n",
        "    \"\"\")\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def save_to_db(user_input, bot_response):\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"INSERT INTO chat_history (user_input, bot_response) VALUES (?, ?)\", (user_input, bot_response))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def fetch_history():\n",
        "    conn = sqlite3.connect(\"chatbot_data.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT * FROM chat_history ORDER BY timestamp DESC LIMIT 10\")\n",
        "    rows = cursor.fetchall()\n",
        "    conn.close()\n",
        "    return rows\n",
        "\n",
        "# Step 2: Set up Tavily search tool\n",
        "tavily_tool = TavilySearchResults(max_results=3)\n",
        "\n",
        "# Step 3: Define the conversation memory\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# Step 4: Define the LLM\n",
        "\n",
        "\n",
        "# Step 5: Initialize tools\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"TavilySearch\",\n",
        "        func=tavily_tool.run,\n",
        "        description=\"Useful for answering questions requiring research or external data.\"\n",
        "    )\n",
        "]\n",
        "\n",
        "# Step 6: Create the conversational agent\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        "    memory=memory,\n",
        ")\n",
        "\n",
        "# Step 7: Implement the chatbot function\n",
        "def chatbot():\n",
        "    print(\"Welcome to the Chatbot! Type 'exit' to end the conversation.\\n\")\n",
        "    print(\"Type 'history' to view the last 10 conversations.\\n\")\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "        elif user_input.lower() == \"history\":\n",
        "            history = fetch_history()\n",
        "            if not history:\n",
        "                print(\"No history found.\")\n",
        "            else:\n",
        "                for idx, (id, user, bot, timestamp) in enumerate(history, 1):\n",
        "                    print(f\"{idx}. {timestamp} - You: {user} | Bot: {bot}\")\n",
        "        else:\n",
        "            response = agent.run(user_input)\n",
        "            print(f\"Bot: {response}\")\n",
        "            save_to_db(user_input, response)\n",
        "\n",
        "# Step 8: Initialize and run the chatbot\n",
        "if __name__ == \"__main__\":\n",
        "    init_db()\n",
        "    chatbot()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVMNi2srmBC8",
        "outputId": "cb97193f-2222-455e-bc13-a157cf7f2f9e"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Chatbot! Type 'exit' to end the conversation.\n",
            "\n",
            "Type 'history' to view the last 10 conversations.\n",
            "\n",
            "You: q\n",
            "Goodbye!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "python.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "google": {
      "image_path": "/static/site-assets/images/docs/logo-python.svg",
      "keywords": [
        "examples",
        "gemini",
        "beginner",
        "googleai",
        "quickstart",
        "python",
        "text",
        "chat",
        "vision",
        "embed"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}